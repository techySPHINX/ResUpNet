{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vp9xvdzC14j",
        "outputId": "cd71adda-8279-454e-e847-8235cd68ab7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Auto-detect environment (Colab vs Local)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    IS_COLAB = True\n",
        "    print(\"âœ… Running on Google Colab\")\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "    print(\"âœ… Running on Local Machine\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBTXxsk-fLU8",
        "outputId": "e433dd3a-cf98-47f9-fd4d-9fae3ddafd4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Version: 2.9.0+cpu\n",
            "CUDA Available: False\n",
            "âš ï¸ No GPU detected. Go to: Runtime > Change runtime type > Select GPU\n"
          ]
        }
      ],
      "source": [
        "# STEP 2: Install/Check PyTorch with GPU Support\n",
        "try:\n",
        "    import torch\n",
        "    print(\"âœ… PyTorch already installed\")\n",
        "except ImportError:\n",
        "    print(\"ðŸ“¦ Installing PyTorch with CUDA 11.8 support...\")\n",
        "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --quiet\n",
        "    import torch\n",
        "\n",
        "# Check GPU Availability\n",
        "print(\"\\nðŸ” GPU Detection:\")\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"âœ… GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸ No GPU detected. Training will use CPU (slower)\")\n",
        "    if IS_COLAB:\n",
        "        print(\"   â†’ Go to: Runtime > Change runtime type > Select GPU\")\n",
        "    else:\n",
        "        print(\"   â†’ Ensure CUDA drivers are installed on your system\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 2b: Check TensorFlow with GPU Support\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    print(\"âœ… TensorFlow already installed\")\n",
        "except ImportError:\n",
        "    print(\"ðŸ“¦ Installing TensorFlow with GPU support...\")\n",
        "    !pip install tensorflow --quiet\n",
        "    import tensorflow as tf\n",
        "\n",
        "print(\"\\nðŸ” TensorFlow GPU Status:\")\n",
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"âœ… {len(gpus)} GPU(s) Available: {gpus}\")\n",
        "    for gpu in gpus:\n",
        "        print(f\"   GPU: {gpu}\")\n",
        "else:\n",
        "    print(\"âš ï¸ No GPU detected by TensorFlow\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "n1im3JxBfCVo",
        "outputId": "38dbf02d-3e60-401f-a7a1-d78ca03c8e71"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# STEP 3 (corrected): Recursive loader for patient subfolders and mask pairing\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Auto-detect dataset path based on environment\n",
        "if IS_COLAB:\n",
        "    # Google Colab path\n",
        "    LGG_ROOT = \"/content/drive/MyDrive/Datasets/Brain MRI segmentation/kaggle_3m\"\n",
        "else:\n",
        "    # Local machine path - adjust this to your actual dataset location\n",
        "    # If you don't have the raw dataset locally, skip this cell and use Cell 6 instead\n",
        "    LGG_ROOT = \"C:/Users/KIIT/Desktop/Datasets/Brain_MRI_segmentation/kaggle_3m\"\n",
        "    if not os.path.exists(LGG_ROOT):\n",
        "        print(\"âš ï¸ Raw dataset not found locally.\")\n",
        "        print(\"   â†’ Skip this cell and run Cell 6 to load preprocessed data directly.\")\n",
        "        LGG_ROOT = None\n",
        "\n",
        "print(f\"Dataset Root: {LGG_ROOT}\")\n",
        "\n",
        "# Supported image/mask extensions (order matters: mask suffix handled separately)\n",
        "IMG_EXTS = (\".tif\", \".tiff\", \".png\", \".jpg\", \".jpeg\")\n",
        "\n",
        "# Containers\n",
        "image_paths = []\n",
        "mask_paths = []\n",
        "\n",
        "def find_pairs_in_patient_folder(patient_folder):\n",
        "    \"\"\"Find (image, mask) pairs inside a patient folder.\n",
        "       Masks are expected to contain '_mask' before the extension (e.g. '..._1_mask.tif').\n",
        "    \"\"\"\n",
        "    files = sorted(os.listdir(patient_folder))\n",
        "    # index files by name for fast lookup\n",
        "    file_set = set(files)\n",
        "    pairs = []\n",
        "\n",
        "    for f in files:\n",
        "        lf = f.lower()\n",
        "        # consider only potential mask files (having '_mask' in name)\n",
        "        if \"_mask\" in lf:\n",
        "            name_no_mask, ext = os.path.splitext(f)\n",
        "            # verify extension\n",
        "            if ext.lower() not in IMG_EXTS:\n",
        "                continue\n",
        "            # derive image filename candidates by removing the last \"_mask\" occurrence\n",
        "            # e.g. \"TCGA_..._1_mask.tif\" -> \"TCGA_..._1.tif\"\n",
        "            img_base = name_no_mask.rsplit(\"_mask\", 1)[0]\n",
        "            # try same extension first\n",
        "            candidate = img_base + ext\n",
        "            if candidate in file_set:\n",
        "                pairs.append((os.path.join(patient_folder, candidate), os.path.join(patient_folder, f)))\n",
        "                continue\n",
        "            # try other extensions if candidate not found\n",
        "            found = False\n",
        "            for e in IMG_EXTS:\n",
        "                candidate_e = img_base + e\n",
        "                if candidate_e in file_set:\n",
        "                    pairs.append((os.path.join(patient_folder, candidate_e), os.path.join(patient_folder, f)))\n",
        "                    found = True\n",
        "                    break\n",
        "            # if not found, skip but report later\n",
        "    return pairs\n",
        "\n",
        "# Walk one level deep in LGG_ROOT (each patient folder contains slices)\n",
        "print(\"Scanning patient folders and pairing image/mask files...\")\n",
        "for entry in sorted(os.listdir(LGG_ROOT)):\n",
        "    p = os.path.join(LGG_ROOT, entry)\n",
        "    if os.path.isdir(p):\n",
        "        pairs = find_pairs_in_patient_folder(p)\n",
        "        for img_p, mask_p in pairs:\n",
        "            image_paths.append(img_p)\n",
        "            mask_paths.append(mask_p)\n",
        "\n",
        "# Safety check\n",
        "if len(image_paths) == 0:\n",
        "    raise FileNotFoundError(f\"No image/mask pairs found under {LGG_ROOT}. Please check the dataset path and folder structure.\")\n",
        "\n",
        "print(f\"Total pairs found: {len(image_paths)}\")\n",
        "\n",
        "# Optional: if dataset is extremely large and limited RAM is available, a subset can be used:\n",
        "# MAX_SAMPLES = 5000\n",
        "# if len(image_paths) > MAX_SAMPLES:\n",
        "#     image_paths = image_paths[:MAX_SAMPLES]\n",
        "#     mask_paths = mask_paths[:MAX_SAMPLES]\n",
        "#     print(f\"Using subset of {MAX_SAMPLES} samples to conserve RAM.\")\n",
        "\n",
        "# Load, preprocess, and store in numpy arrays\n",
        "IMG_SIZE = 256  # target size\n",
        "images = []\n",
        "masks = []\n",
        "\n",
        "print(\"Loading and preprocessing images (this may take a while)...\")\n",
        "for img_p, mask_p in tqdm(zip(image_paths, mask_paths), total=len(image_paths)):\n",
        "    # read image - keep as grayscale\n",
        "    img = cv2.imread(img_p, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = cv2.imread(mask_p, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if img is None or mask is None:\n",
        "        # Skip corrupted or unreadable files but report\n",
        "        print(f\"Warning: failed to read pair: {img_p} / {mask_p}\")\n",
        "        continue\n",
        "\n",
        "    # Resize\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_LINEAR)\n",
        "    mask = cv2.resize(mask, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    # Normalize image to [0,1]\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "\n",
        "    # Binarize mask: treat any non-zero as tumour (0/1)\n",
        "    mask = (mask > 0).astype(np.float32)\n",
        "\n",
        "    # Add channel dimension\n",
        "    img = np.expand_dims(img, axis=-1)   # shape (H,W,1)\n",
        "    mask = np.expand_dims(mask, axis=-1) # shape (H,W,1)\n",
        "\n",
        "    images.append(img)\n",
        "    masks.append(mask)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "images = np.array(images, dtype=np.float32)\n",
        "masks = np.array(masks, dtype=np.float32)\n",
        "\n",
        "print(\"Preprocessing finished.\")\n",
        "print(\"Images shape:\", images.shape)\n",
        "print(\"Masks shape: \", masks.shape)\n",
        "\n",
        "# Shuffle and split: Train 70%, Val 15%, Test 15%\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, masks, test_size=0.30, random_state=42, shuffle=True)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, shuffle=True)\n",
        "\n",
        "print(\"\\nDataset split:\")\n",
        "print(\"Training set:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
        "print(\"Test set:\", X_test.shape, y_test.shape)\n",
        "\n",
        "# Quick sanity visualisation of 4 random samples\n",
        "import random\n",
        "idxs = random.sample(range(len(X_train)), min(4, len(X_train)))\n",
        "fig, axs = plt.subplots(4, 2, figsize=(8, 12))\n",
        "\n",
        "for i, idx in enumerate(idxs):\n",
        "    axs[i,0].imshow(X_train[idx].squeeze(), cmap='gray')\n",
        "    axs[i,0].set_title(\"Input\")\n",
        "    axs[i,1].imshow(y_train[idx].squeeze(), cmap='gray')\n",
        "    axs[i,1].set_title(\"Mask\")\n",
        "    axs[i,0].axis('off'); axs[i,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkchei4DfCRC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj5rbG5pC11F",
        "outputId": "a3451fe6-2409-46e1-e2be-780a147618ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (2750, 256, 256, 1) (2750, 256, 256, 1)\n",
            "Val  : (589, 256, 256, 1) (589, 256, 256, 1)\n",
            "Test : (590, 256, 256, 1) (590, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Auto-detect preprocessed data path\n",
        "if IS_COLAB:\n",
        "    BASE_PATH = \"/content/drive/MyDrive/LGGData/processed_splits\"\n",
        "else:\n",
        "    # Local machine - use the processed_splits folder in current directory\n",
        "    BASE_PATH = \"processed_splits\"\n",
        "    # Or use absolute path:\n",
        "    # BASE_PATH = \"C:/Users/KIIT/Desktop/open-source/resunet/processed_splits\"\n",
        "\n",
        "print(f\"ðŸ“‚ Loading preprocessed data from: {BASE_PATH}\")\n",
        "\n",
        "if not os.path.exists(BASE_PATH):\n",
        "    raise FileNotFoundError(f\"âŒ Preprocessed data not found at: {BASE_PATH}\")\n",
        "\n",
        "X_train = np.load(f\"{BASE_PATH}/X_train.npy\")\n",
        "y_train = np.load(f\"{BASE_PATH}/y_train.npy\")\n",
        "\n",
        "X_val   = np.load(f\"{BASE_PATH}/X_val.npy\")\n",
        "y_val   = np.load(f\"{BASE_PATH}/y_val.npy\")\n",
        "\n",
        "X_test  = np.load(f\"{BASE_PATH}/X_test.npy\")\n",
        "y_test  = np.load(f\"{BASE_PATH}/y_test.npy\")\n",
        "\n",
        "print(\"\\nâœ… Data loaded successfully:\")\n",
        "print(\"   Train:\", X_train.shape, y_train.shape)\n",
        "print(\"   Val  :\", X_val.shape, y_val.shape)\n",
        "print(\"   Test :\", X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_9R-OjQggxJ"
      },
      "source": [
        "\n",
        "\n",
        "### Step 4: Building the ResUpNet Model (Residual U-Net + ResNet50 Encoder + Attention Skip Fusion)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2ZAYUKoC-CZg"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, backend as K\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.spatial.distance as sdist\n",
        "import cv2\n",
        "import os\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return 1 - (2. * intersection + smooth) / (\n",
        "        tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth\n",
        "    )\n",
        "\n",
        "def combo_loss(y_true, y_pred):\n",
        "    return dice_loss(y_true, y_pred) + tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    def loss_fn(y_true, y_pred):\n",
        "        y_true_f = K.flatten(y_true)\n",
        "        y_pred_f = K.flatten(y_pred)\n",
        "        eps = K.epsilon()\n",
        "        y_pred_f = K.clip(y_pred_f, eps, 1. - eps)\n",
        "        pt = tf.where(tf.equal(y_true_f, 1), y_pred_f, 1 - y_pred_f)\n",
        "        w = alpha * K.pow(1. - pt, gamma)\n",
        "        fl = - w * K.log(pt)\n",
        "        return K.mean(fl)\n",
        "    return loss_fn\n",
        "\n",
        "def hybrid_loss(alpha=0.5, gamma=2.0):\n",
        "    fl = focal_loss(gamma=gamma, alpha=0.25)\n",
        "    def loss(y_true, y_pred):\n",
        "        return alpha * dice_loss(y_true, y_pred) + (1.0 - alpha) * fl(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "def iou_metric(y_true, y_pred, thresh=0.5, smooth=1e-6):\n",
        "    y_pred = tf.cast(y_pred > thresh, tf.float32)\n",
        "    inter = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - inter\n",
        "    return (inter + smooth) / (union + smooth)\n",
        "\n",
        "\n",
        "\n",
        "def iou_keras(y_true, y_pred): return iou_metric(y_true, y_pred)\n",
        "def precision_keras(y_true, y_pred):\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
        "    tp = tf.reduce_sum(y_true * y_pred)\n",
        "    predicted_positive = tf.reduce_sum(y_pred)\n",
        "    return tp / (predicted_positive + K.epsilon())\n",
        "\n",
        "def recall_keras(y_true, y_pred):\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
        "    tp = tf.reduce_sum(y_true * y_pred)\n",
        "    actual_positive = tf.reduce_sum(y_true)\n",
        "    return tp / (actual_positive + K.epsilon())\n",
        "\n",
        "def f1_keras(y_true, y_pred):\n",
        "    p = precision_keras(y_true, y_pred)\n",
        "    r = recall_keras(y_true, y_pred)\n",
        "    return 2 * p * r / (p + r + K.epsilon())\n",
        "\n",
        "\n",
        "def attention_gate(x, g, inter_channels):\n",
        "    \"\"\"\n",
        "    Simple attention gate as in Attention U-Net.\n",
        "    x: skip connection feature map\n",
        "    g: gating signal (decoder)\n",
        "    \"\"\"\n",
        "    theta_x = layers.Conv2D(inter_channels, 1, strides=1, padding='same')(x)\n",
        "    phi_g = layers.Conv2D(inter_channels, 1, strides=1, padding='same')(g)\n",
        "    add = layers.Add()([theta_x, phi_g])\n",
        "    relu = layers.Activation('relu')(add)\n",
        "    psi = layers.Conv2D(1, 1, strides=1, padding='same')(relu)\n",
        "    sig = layers.Activation('sigmoid')(psi)\n",
        "\n",
        "\n",
        "    out = layers.Multiply()([x, sig])\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "def residual_conv_block(x, filters, kernel_size=3):\n",
        "    shortcut = x\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    # Project shortcut if needed\n",
        "    if shortcut.shape[-1] != filters:\n",
        "        shortcut = layers.Conv2D(filters, 1, padding='same')(shortcut)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def build_resupnet(input_shape=(256,256,1), pretrained=True, train_encoder=True):\n",
        "    \"\"\"\n",
        "    ResUpNet:\n",
        "     - input_shape: grayscale (H,W,1)\n",
        "     - pretrained: use ImageNet weights for ResNet50 encoder\n",
        "     - train_encoder: whether encoder layers are trainable\n",
        "    \"\"\"\n",
        "    # Input and convert to 3-channel required by ResNet50\n",
        "    inp = layers.Input(shape=input_shape, name='input_image')\n",
        "    # repeat channels to make 3 channels\n",
        "    x = layers.Concatenate()([inp, inp, inp])  # shape -> (H,W,3)\n",
        "\n",
        "    # Pretrained ResNet50 encoder\n",
        "    base = ResNet50(include_top=False, weights='imagenet' if pretrained else None, input_tensor=x)\n",
        "    base.trainable = train_encoder\n",
        "\n",
        "    skips = [\n",
        "        base.get_layer('conv1_relu').output,         # 128x128\n",
        "        base.get_layer('conv2_block3_out').output,   # 64x64\n",
        "        base.get_layer('conv3_block4_out').output,   # 32x32\n",
        "        base.get_layer('conv4_block6_out').output    # 16x16\n",
        "    ]\n",
        "    bottleneck = base.get_layer('conv5_block3_out').output  # 8x8\n",
        "\n",
        "    # Decoder: progressive upsampling, attention on skip, residual conv blocks\n",
        "    d = bottleneck\n",
        "    filters = [512, 256, 128, 64]  # matching decoder filters\n",
        "\n",
        "    for i, f in enumerate(filters):\n",
        "        # upsample\n",
        "        d = layers.UpSampling2D(size=(2,2), interpolation='bilinear')(d)\n",
        "        # attention gate on skip connection\n",
        "        skip = skips[-(i+1)]\n",
        "        att = attention_gate(skip, d, inter_channels=f//4)\n",
        "        # concatenate\n",
        "        d = layers.Concatenate()([d, att])\n",
        "        # residual conv block\n",
        "        d = residual_conv_block(d, f)\n",
        "\n",
        "    # Final upsample to original resolution (from 128 -> 256 if needed)\n",
        "    d = layers.UpSampling2D(size=(2,2), interpolation='bilinear')(d)\n",
        "    d = residual_conv_block(d, 32)\n",
        "\n",
        "    # Output\n",
        "    out = layers.Conv2D(1, (1,1), padding='same', activation='sigmoid', name='mask')(d)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=out, name='ResUpNet')\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gdo_SIJG-CXD",
        "outputId": "d280c07f-7d7d-4cdb-c971-47d93d602be9"
      },
      "outputs": [],
      "source": [
        "model = build_resupnet()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=combo_loss,\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        dice_coef,\n",
        "        tf.keras.metrics.MeanIoU(num_classes=2)\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbqOGxmoURSZ"
      },
      "outputs": [],
      "source": [
        "#2nd trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Lrk_kUPrQvW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.spatial.distance as sdist\n",
        "from skimage import measure\n",
        "\n",
        "\n",
        "\n",
        "def dice_np(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    inter = np.sum(y_true_f * y_pred_f)\n",
        "    return (2. * inter + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
        "\n",
        "def iou_np(y_true, y_pred, smooth=1e-6):\n",
        "    inter = np.sum(y_true * y_pred)\n",
        "    union = np.sum(y_true) + np.sum(y_pred) - inter\n",
        "    return (inter + smooth) / (union + smooth)\n",
        "\n",
        "def precision_np(y_true, y_pred, smooth=1e-6):\n",
        "    tp = np.sum(y_true * y_pred)\n",
        "    fp = np.sum((1 - y_true) * y_pred)\n",
        "    return tp / (tp + fp + smooth)\n",
        "\n",
        "def recall_np(y_true, y_pred, smooth=1e-6):\n",
        "    tp = np.sum(y_true * y_pred)\n",
        "    fn = np.sum(y_true * (1 - y_pred))\n",
        "    return tp / (tp + fn + smooth)\n",
        "\n",
        "def f1_np(y_true, y_pred, smooth=1e-6):\n",
        "    p = precision_np(y_true, y_pred)\n",
        "    r = recall_np(y_true, y_pred)\n",
        "    return (2 * p * r) / (p + r + smooth)\n",
        "\n",
        "def specificity_np(y_true, y_pred, smooth=1e-6):\n",
        "    tn = np.sum((1 - y_true) * (1 - y_pred))\n",
        "    fp = np.sum((1 - y_true) * y_pred)\n",
        "    return tn / (tn + fp + smooth)\n",
        "\n",
        "def hd95_np(y_true, y_pred):\n",
        "    y_true_pts = np.argwhere(y_true > 0)\n",
        "    y_pred_pts = np.argwhere(y_pred > 0)\n",
        "\n",
        "    if len(y_true_pts) == 0 or len(y_pred_pts) == 0:\n",
        "        return 0.0  # safe fallback\n",
        "\n",
        "    d1 = sdist.cdist(y_true_pts, y_pred_pts)\n",
        "    d2 = sdist.cdist(y_pred_pts, y_true_pts)\n",
        "    return max(np.percentile(d1.min(axis=1), 95),\n",
        "               np.percentile(d2.min(axis=1), 95))\n",
        "\n",
        "def asd_np(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Average Surface Distance (ASD)\n",
        "    Computes mean bidirectional surface distance\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure binary\n",
        "    y_true = y_true.squeeze()\n",
        "    y_pred = y_pred.squeeze()\n",
        "\n",
        "    # Extract contours (surface pixels)\n",
        "    true_contours = measure.find_contours(y_true, 0.5)\n",
        "    pred_contours = measure.find_contours(y_pred, 0.5)\n",
        "\n",
        "    if len(true_contours) == 0 or len(pred_contours) == 0:\n",
        "        return 0.0  # safe fallback (no tumor)\n",
        "\n",
        "    # Stack contour points\n",
        "    true_pts = np.vstack(true_contours)\n",
        "    pred_pts = np.vstack(pred_contours)\n",
        "\n",
        "    # Pairwise distances\n",
        "    d_true_to_pred = sdist.cdist(true_pts, pred_pts)\n",
        "    d_pred_to_true = sdist.cdist(pred_pts, true_pts)\n",
        "\n",
        "    # Mean of minimum distances\n",
        "    asd = (np.mean(d_true_to_pred.min(axis=1)) +\n",
        "           np.mean(d_pred_to_true.min(axis=1))) / 2.0\n",
        "\n",
        "    return asd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLUozy04yDSb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.spatial.distance as sdist\n",
        "\n",
        "class EpochEvaluationCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, X_val, y_val, threshold=0.5, max_samples=None):\n",
        "        super().__init__()\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.threshold = threshold\n",
        "        self.max_samples = max_samples\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        all_dice, all_iou, all_prec, all_rec, all_f1 = [], [], [], [], []\n",
        "        all_hd95, all_asd = [], []\n",
        "\n",
        "        idxs = range(len(self.X_val))\n",
        "        if self.max_samples:\n",
        "            idxs = list(idxs)[:self.max_samples]\n",
        "\n",
        "        for i in idxs:\n",
        "            x = self.X_val[i:i+1]\n",
        "            y_true = self.y_val[i].squeeze()\n",
        "\n",
        "            y_prob = self.model.predict(x, verbose=0)[0, ..., 0]\n",
        "            y_pred = (y_prob > self.threshold).astype(np.float32)\n",
        "\n",
        "            d = dice_np(y_true, y_pred)\n",
        "            j = iou_np(y_true, y_pred)\n",
        "            p = precision_np(y_true, y_pred)\n",
        "            r = recall_np(y_true, y_pred)\n",
        "            f1 = f1_np(y_true, y_pred)\n",
        "\n",
        "            h = hd95_np(y_true, y_pred)\n",
        "            a = asd_np(y_true, y_pred)\n",
        "\n",
        "            all_dice.append(d)\n",
        "            all_iou.append(j)\n",
        "            all_prec.append(p)\n",
        "            all_rec.append(r)\n",
        "            all_f1.append(f1)\n",
        "            all_hd95.append(h)\n",
        "            all_asd.append(a)\n",
        "\n",
        "        print(f\"\\nðŸ“Š Epoch {epoch+1} â€” Validation Metrics:\")\n",
        "        print(f\"Dice:      {np.nanmean(all_dice):.4f}\")\n",
        "        print(f\"IoU:       {np.nanmean(all_iou):.4f}\")\n",
        "        print(f\"Precision: {np.nanmean(all_prec):.4f}\")\n",
        "        print(f\"Recall:    {np.nanmean(all_rec):.4f}\")\n",
        "        print(f\"F1:        {np.nanmean(all_f1):.4f}\")\n",
        "        print(f\"HD95(px):  {np.nanmean(all_hd95):.2f}\")\n",
        "        print(f\"ASD(px):   {np.nanmean(all_asd):.2f}\")\n",
        "\n",
        "\n",
        "epoch_eval_cb = EpochEvaluationCallback(\n",
        "    X_val, y_val,\n",
        "    threshold=0.5,\n",
        "    max_samples=50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUnpbpW5ezHp"
      },
      "outputs": [],
      "source": [
        "epoch_eval_cb = EpochEvaluationCallback(\n",
        "    X_val, y_val,\n",
        "    threshold=0.5,# or equal to 0.45(optimal-callback rerun it in case of bad outputs)\n",
        "    max_samples=50\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "pHNdiabGyDPF",
        "outputId": "777ec2cb-a412-47ec-8f4e-0514b483d790"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.callbacks import (\n",
        "    ModelCheckpoint,\n",
        "    ReduceLROnPlateau,\n",
        "    EarlyStopping\n",
        ")\n",
        "\n",
        "import scipy.spatial.distance as sdist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        \"best_resupnet.keras\",\n",
        "        monitor=\"val_dice_coef\",\n",
        "        save_best_only=True,\n",
        "        mode=\"max\",\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor=\"val_dice_coef\",\n",
        "        factor=0.50,\n",
        "        patience=3,\n",
        "        min_lr=1e-6,\n",
        "        mode=\"max\",\n",
        "        verbose=1\n",
        "    ),EarlyStopping(\n",
        "    monitor=\"val_dice_coef\",\n",
        "    mode=\"max\",\n",
        "    patience=8,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        ",\n",
        "    epoch_eval_cb\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OijWu8CI307Q"
      },
      "outputs": [],
      "source": [
        "### NORMAL PLOTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re4OTRc33gX7"
      },
      "outputs": [],
      "source": [
        "history_dict = history.history\n",
        "\n",
        "train_loss = history_dict['loss']\n",
        "val_loss   = history_dict['val_loss']\n",
        "\n",
        "train_dice = history_dict['dice_coef']\n",
        "val_dice   = history_dict['val_dice_coef']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGAPoEed3gVe"
      },
      "outputs": [],
      "source": [
        "lrs = []\n",
        "optimizer = model.optimizer\n",
        "\n",
        "for i in range(len(epochs)):\n",
        "    lrs.append(tf.keras.backend.get_value(optimizer.learning_rate))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkaDln-W3nmD"
      },
      "outputs": [],
      "source": [
        "dice_gap = np.array(train_dice) - np.array(val_dice)\n",
        "loss_gap = np.array(val_loss) - np.array(train_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCxOIT1H3nan"
      },
      "outputs": [],
      "source": [
        "best_val_dice = []\n",
        "current_best = 0\n",
        "\n",
        "for d in val_dice:\n",
        "    current_best = max(current_best, d)\n",
        "    best_val_dice.append(current_best)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lp-RnGTm3uKb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 12))\n",
        "\n",
        "# ---- 1. Training vs Validation Loss ----\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.plot(epochs, train_loss, 'bo-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# ---- 2. Training vs Validation Dice ----\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(epochs, train_dice, 'bo-', label='Training Dice Coef')\n",
        "plt.plot(epochs, val_dice, 'ro-', label='Validation Dice Coef')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Dice Coefficient')\n",
        "plt.title('Training vs Validation Dice Coefficient')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# ---- 3. Learning Rate Schedule ----\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.plot(epochs, lrs, 'mo-', linewidth=2)\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.title('Learning Rate Schedule (ReduceLROnPlateau)')\n",
        "plt.grid(True)\n",
        "\n",
        "# ---- 4. Dice Generalization Gap ----\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.plot(epochs, dice_gap, color='orange', marker='o')\n",
        "plt.fill_between(epochs, dice_gap, alpha=0.3, color='orange')\n",
        "plt.axhline(0, linestyle='--', color='black')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Dice Gap (Train - Val)')\n",
        "plt.title('Generalization Gap (Dice Coefficient)')\n",
        "plt.grid(True)\n",
        "\n",
        "# ---- 5. Loss Generalization Gap ----\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.plot(epochs, loss_gap, color='salmon', marker='o')\n",
        "plt.fill_between(epochs, loss_gap, alpha=0.3, color='salmon')\n",
        "plt.axhline(0, linestyle='--', color='black')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Gap (Val - Train)')\n",
        "plt.title('Generalization Gap (Loss)')\n",
        "plt.grid(True)\n",
        "\n",
        "# ---- 6. Best Model Progression ----\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.plot(epochs, best_val_dice, 'g*-', linewidth=2)\n",
        "for i, v in enumerate(best_val_dice):\n",
        "    if i % 5 == 0 or i == len(best_val_dice) - 1:\n",
        "        plt.text(i + 1, v, f\"{v:.4f}\", fontsize=9)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Dice Coefficient')\n",
        "plt.title('Best Model Progression')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJrEyBkMg-RL"
      },
      "outputs": [],
      "source": [
        "###COMPARISIONPLOTS###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpcvvsuW-QPF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training(history):\n",
        "    epochs = range(1, len(history.history['loss']) + 1)\n",
        "\n",
        "# training vs epoch plots\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.plot(epochs, history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(epochs, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('accuracy_curve.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # loss plots\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.plot(epochs, history.history['loss'], label='Training Loss')\n",
        "    plt.plot(epochs, history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('loss_curve.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    if 'mean_io_u' in history.history:\n",
        "        plt.figure(figsize=(6,5))\n",
        "        plt.plot(epochs, history.history['mean_io_u'], label='Training IoU')\n",
        "        plt.plot(epochs, history.history['val_mean_io_u'], label='Validation IoU')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Mean IoU')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('iou_curve.png', dpi=300)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTRGSTh7LxI1"
      },
      "outputs": [],
      "source": [
        "#### BLAND ANALYSIS PLOTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiItHBycLxFQ"
      },
      "outputs": [],
      "source": [
        "def compute_volumes(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    y_true, y_pred: binary masks (H, W) or (H, W, D)\n",
        "    returns volume (number of positive pixels/voxels)\n",
        "    \"\"\"\n",
        "    return np.sum(y_true), np.sum(y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjSfIw_GhHSi"
      },
      "outputs": [],
      "source": [
        "gt_volumes = []\n",
        "pred_volumes = []\n",
        "\n",
        "threshold = 0.5\n",
        "max_samples = 50\n",
        "\n",
        "for i in range(max_samples):\n",
        "    x = X_val[i:i+1]\n",
        "    y_true = y_val[i].squeeze()\n",
        "\n",
        "    y_prob = model.predict(x, verbose=0)[0, ..., 0]\n",
        "    y_pred = (y_prob > threshold).astype(np.float32)\n",
        "\n",
        "    gt_v, pred_v = compute_volumes(y_true, y_pred)\n",
        "\n",
        "    gt_volumes.append(gt_v)\n",
        "    pred_volumes.append(pred_v)\n",
        "\n",
        "gt_volumes = np.array(gt_volumes)\n",
        "pred_volumes = np.array(pred_volumes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aTo52hwhHs3"
      },
      "outputs": [],
      "source": [
        "means = (gt_volumes + pred_volumes) / 2\n",
        "diffs = pred_volumes - gt_volumes\n",
        "\n",
        "mean_diff = np.mean(diffs)\n",
        "std_diff = np.std(diffs)\n",
        "\n",
        "loa_upper = mean_diff + 1.96 * std_diff\n",
        "loa_lower = mean_diff - 1.96 * std_diff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iWcoavrhNeO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "\n",
        "plt.scatter(means, diffs, alpha=0.7)\n",
        "plt.axhline(mean_diff, linestyle='--', linewidth=2, label=f'Mean diff = {mean_diff:.2f}')\n",
        "plt.axhline(loa_upper, linestyle='--', linewidth=2, label=f'+1.96 SD = {loa_upper:.2f}')\n",
        "plt.axhline(loa_lower, linestyle='--', linewidth=2, label=f'-1.96 SD = {loa_lower:.2f}')\n",
        "\n",
        "plt.xlabel('Mean of GT and Predicted Volume')\n",
        "plt.ylabel('Difference (Pred âˆ’ GT)')\n",
        "plt.title('Blandâ€“Altman Analysis')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('bland_altman_volume.png', dpi=300)\n",
        "plt.show()\n",
        "### for ground truth image this plot is needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nMF3CCkyUMi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Additional Visualizations - Test Set Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Distribution of Metrics Across Test Set\n",
        "print(\"Computing metrics for all test samples...\")\n",
        "test_dice, test_iou, test_prec, test_rec = [], [], [], []\n",
        "test_f1, test_hd95, test_asd = [], [], []\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    x = X_test[i:i+1]\n",
        "    y_true = y_test[i].squeeze()\n",
        "    \n",
        "    y_prob = model.predict(x, verbose=0)[0, ..., 0]\n",
        "    y_pred = (y_prob > threshold).astype(np.float32)\n",
        "    \n",
        "    test_dice.append(dice_np(y_true, y_pred))\n",
        "    test_iou.append(iou_np(y_true, y_pred))\n",
        "    test_prec.append(precision_np(y_true, y_pred))\n",
        "    test_rec.append(recall_np(y_true, y_pred))\n",
        "    test_f1.append(f1_np(y_true, y_pred))\n",
        "    test_hd95.append(hd95_np(y_true, y_pred))\n",
        "    test_asd.append(asd_np(y_true, y_pred))\n",
        "\n",
        "print(\"âœ… Metrics computed for all test samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Box Plots for All Metrics\n",
        "plt.figure(figsize=(16, 10))\n",
        "\n",
        "metrics_data = {\n",
        "    'Dice': test_dice,\n",
        "    'IoU': test_iou,\n",
        "    'Precision': test_prec,\n",
        "    'Recall': test_rec,\n",
        "    'F1': test_f1\n",
        "}\n",
        "\n",
        "# Subplot 1: Main segmentation metrics\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.boxplot(metrics_data.values(), labels=metrics_data.keys())\n",
        "plt.ylabel('Score')\n",
        "plt.title('Distribution of Segmentation Metrics on Test Set')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.ylim([0, 1.05])\n",
        "\n",
        "# Add mean values\n",
        "for i, (name, values) in enumerate(metrics_data.items(), 1):\n",
        "    mean_val = np.mean(values)\n",
        "    plt.text(i, mean_val, f'{mean_val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Subplot 2: Distance metrics\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.boxplot([test_hd95, test_asd], labels=['HD95 (px)', 'ASD (px)'])\n",
        "plt.ylabel('Distance (pixels)')\n",
        "plt.title('Distribution of Distance Metrics on Test Set')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Subplot 3: Dice Score Distribution (Histogram)\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.hist(test_dice, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "plt.axvline(np.mean(test_dice), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(test_dice):.4f}')\n",
        "plt.axvline(np.median(test_dice), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(test_dice):.4f}')\n",
        "plt.xlabel('Dice Coefficient')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Dice Score Distribution')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Subplot 4: IoU Score Distribution (Histogram)\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.hist(test_iou, bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "plt.axvline(np.mean(test_iou), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(test_iou):.4f}')\n",
        "plt.axvline(np.median(test_iou), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(test_iou):.4f}')\n",
        "plt.xlabel('IoU Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('IoU Score Distribution')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('test_metrics_distribution.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Correlation Heatmap Between Metrics\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "metrics_df = {\n",
        "    'Dice': test_dice,\n",
        "    'IoU': test_iou,\n",
        "    'Precision': test_prec,\n",
        "    'Recall': test_rec,\n",
        "    'F1': test_f1,\n",
        "    'HD95': test_hd95,\n",
        "    'ASD': test_asd\n",
        "}\n",
        "\n",
        "# Create correlation matrix\n",
        "df = pd.DataFrame(metrics_df)\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0, \n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Correlation Matrix of Evaluation Metrics', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('metrics_correlation_heatmap.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Scatter Plot: Predicted vs Ground Truth Volumes\n",
        "gt_test_volumes = []\n",
        "pred_test_volumes = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    x = X_test[i:i+1]\n",
        "    y_true = y_test[i].squeeze()\n",
        "    \n",
        "    y_prob = model.predict(x, verbose=0)[0, ..., 0]\n",
        "    y_pred = (y_prob > threshold).astype(np.float32)\n",
        "    \n",
        "    gt_v, pred_v = compute_volumes(y_true, y_pred)\n",
        "    gt_test_volumes.append(gt_v)\n",
        "    pred_test_volumes.append(pred_v)\n",
        "\n",
        "gt_test_volumes = np.array(gt_test_volumes)\n",
        "pred_test_volumes = np.array(pred_test_volumes)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(gt_test_volumes, pred_test_volumes, alpha=0.6, s=50, edgecolors='black')\n",
        "\n",
        "# Perfect prediction line\n",
        "max_vol = max(gt_test_volumes.max(), pred_test_volumes.max())\n",
        "plt.plot([0, max_vol], [0, max_vol], 'r--', linewidth=2, label='Perfect Prediction')\n",
        "\n",
        "# Add correlation coefficient\n",
        "corr, p_value = pearsonr(gt_test_volumes, pred_test_volumes)\n",
        "plt.text(0.05, 0.95, f'Pearson r = {corr:.4f}\\np-value = {p_value:.4e}', \n",
        "         transform=plt.gca().transAxes, fontsize=12, verticalalignment='top',\n",
        "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "plt.xlabel('Ground Truth Volume (pixels)', fontsize=12)\n",
        "plt.ylabel('Predicted Volume (pixels)', fontsize=12)\n",
        "plt.title('Predicted vs Ground Truth Tumor Volume', fontsize=14, fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('volume_scatter_plot.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Best, Worst, and Median Predictions Visualization\n",
        "# Find best, worst, and median cases based on Dice score\n",
        "dice_with_idx = [(d, i) for i, d in enumerate(test_dice)]\n",
        "dice_with_idx.sort(key=lambda x: x[0])\n",
        "\n",
        "worst_idx = dice_with_idx[0][1]\n",
        "median_idx = dice_with_idx[len(dice_with_idx)//2][1]\n",
        "best_idx = dice_with_idx[-1][1]\n",
        "\n",
        "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
        "\n",
        "cases = [\n",
        "    ('Worst', worst_idx, test_dice[worst_idx]),\n",
        "    ('Median', median_idx, test_dice[median_idx]),\n",
        "    ('Best', best_idx, test_dice[best_idx])\n",
        "]\n",
        "\n",
        "for row, (label, idx, dice_score) in enumerate(cases):\n",
        "    x = X_test[idx:idx+1]\n",
        "    y_true = y_test[idx].squeeze()\n",
        "    \n",
        "    y_prob = model.predict(x, verbose=0)[0, ..., 0]\n",
        "    y_pred = (y_prob > threshold).astype(np.float32)\n",
        "    \n",
        "    # Original image\n",
        "    axes[row, 0].imshow(X_test[idx].squeeze(), cmap='gray')\n",
        "    axes[row, 0].set_title(f'{label} Case - Input\\nDice: {dice_score:.4f}')\n",
        "    axes[row, 0].axis('off')\n",
        "    \n",
        "    # Ground truth\n",
        "    axes[row, 1].imshow(y_true, cmap='gray')\n",
        "    axes[row, 1].set_title('Ground Truth')\n",
        "    axes[row, 1].axis('off')\n",
        "    \n",
        "    # Prediction\n",
        "    axes[row, 2].imshow(y_pred, cmap='gray')\n",
        "    axes[row, 2].set_title('Prediction')\n",
        "    axes[row, 2].axis('off')\n",
        "    \n",
        "    # Overlay\n",
        "    overlay = X_test[idx].squeeze()\n",
        "    axes[row, 3].imshow(overlay, cmap='gray')\n",
        "    axes[row, 3].contour(y_true, colors='green', linewidths=2, alpha=0.7, label='GT')\n",
        "    axes[row, 3].contour(y_pred, colors='red', linewidths=2, alpha=0.7, label='Pred')\n",
        "    axes[row, 3].set_title('Overlay (Green=GT, Red=Pred)')\n",
        "    axes[row, 3].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('best_worst_median_predictions.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. ROC Curve and Precision-Recall Curve\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "\n",
        "# Collect all predictions and ground truths\n",
        "all_y_true = []\n",
        "all_y_pred_prob = []\n",
        "\n",
        "print(\"Generating probability predictions for ROC/PR curves...\")\n",
        "for i in range(len(X_test)):\n",
        "    x = X_test[i:i+1]\n",
        "    y_true = y_test[i].squeeze()\n",
        "    \n",
        "    y_prob = model.predict(x, verbose=0)[0, ..., 0]\n",
        "    \n",
        "    all_y_true.extend(y_true.flatten())\n",
        "    all_y_pred_prob.extend(y_prob.flatten())\n",
        "\n",
        "all_y_true = np.array(all_y_true)\n",
        "all_y_pred_prob = np.array(all_y_pred_prob)\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds_roc = roc_curve(all_y_true, all_y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, thresholds_pr = precision_recall_curve(all_y_true, all_y_pred_prob)\n",
        "avg_precision = average_precision_score(all_y_true, all_y_pred_prob)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# ROC Curve\n",
        "ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
        "ax1.set_xlim([0.0, 1.0])\n",
        "ax1.set_ylim([0.0, 1.05])\n",
        "ax1.set_xlabel('False Positive Rate', fontsize=12)\n",
        "ax1.set_ylabel('True Positive Rate', fontsize=12)\n",
        "ax1.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
        "ax1.legend(loc=\"lower right\")\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Precision-Recall Curve\n",
        "ax2.plot(recall, precision, color='blue', lw=2, label=f'PR curve (AP = {avg_precision:.4f})')\n",
        "ax2.set_xlim([0.0, 1.0])\n",
        "ax2.set_ylim([0.0, 1.05])\n",
        "ax2.set_xlabel('Recall', fontsize=12)\n",
        "ax2.set_ylabel('Precision', fontsize=12)\n",
        "ax2.set_title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
        "ax2.legend(loc=\"lower left\")\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('roc_pr_curves.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nðŸ“Š ROC AUC: {roc_auc:.4f}\")\n",
        "print(f\"ðŸ“Š Average Precision: {avg_precision:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Confusion Matrix (Pixel-wise)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Binarize predictions\n",
        "all_y_pred_binary = (all_y_pred_prob > threshold).astype(int)\n",
        "\n",
        "cm = confusion_matrix(all_y_true, all_y_pred_binary)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', square=True, \n",
        "            xticklabels=['Background', 'Tumor'], \n",
        "            yticklabels=['Background', 'Tumor'],\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.title('Confusion Matrix (Pixel-wise)', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Add percentages\n",
        "total = cm.sum()\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        percentage = (cm[i, j] / total) * 100\n",
        "        plt.text(j + 0.5, i + 0.7, f'({percentage:.2f}%)', \n",
        "                ha='center', va='center', fontsize=10, color='red')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "sensitivity = tp / (tp + fn)\n",
        "\n",
        "print(f\"\\nðŸ“Š Pixel-wise Metrics:\")\n",
        "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Error Analysis - Cases with Low Dice Scores\n",
        "low_dice_threshold = 0.70\n",
        "low_dice_cases = [(d, i) for i, d in enumerate(test_dice) if d < low_dice_threshold]\n",
        "\n",
        "if len(low_dice_cases) > 0:\n",
        "    print(f\"Found {len(low_dice_cases)} cases with Dice < {low_dice_threshold}\")\n",
        "    \n",
        "    # Visualize up to 9 low-performing cases\n",
        "    n_display = min(9, len(low_dice_cases))\n",
        "    low_dice_cases_sorted = sorted(low_dice_cases, key=lambda x: x[0])[:n_display]\n",
        "    \n",
        "    rows = int(np.ceil(n_display / 3))\n",
        "    fig, axes = plt.subplots(rows, 3, figsize=(15, 5 * rows))\n",
        "    axes = axes.flatten() if n_display > 1 else [axes]\n",
        "    \n",
        "    for plot_idx, (dice_score, idx) in enumerate(low_dice_cases_sorted):\n",
        "        x = X_test[idx:idx+1]\n",
        "        y_true = y_test[idx].squeeze()\n",
        "        \n",
        "        y_prob = model.predict(x, verbose=0)[0, ..., 0]\n",
        "        y_pred = (y_prob > threshold).astype(np.float32)\n",
        "        \n",
        "        # Overlay visualization\n",
        "        overlay = X_test[idx].squeeze()\n",
        "        axes[plot_idx].imshow(overlay, cmap='gray')\n",
        "        axes[plot_idx].contour(y_true, colors='green', linewidths=2, alpha=0.7)\n",
        "        axes[plot_idx].contour(y_pred, colors='red', linewidths=2, alpha=0.7)\n",
        "        axes[plot_idx].set_title(f'Sample {idx}\\nDice: {dice_score:.4f}\\nIoU: {test_iou[idx]:.4f}')\n",
        "        axes[plot_idx].axis('off')\n",
        "    \n",
        "    # Hide unused subplots\n",
        "    for i in range(n_display, len(axes)):\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.suptitle(f'Error Analysis - Cases with Dice < {low_dice_threshold}\\n(Green=GT, Red=Pred)', \n",
        "                 fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('error_analysis_low_dice.png', dpi=300)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"âœ… All test cases have Dice >= {low_dice_threshold}!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Comprehensive Summary Statistics Table\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š COMPREHENSIVE TEST SET EVALUATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "summary_stats = {\n",
        "    'Metric': ['Dice Coefficient', 'IoU', 'Precision', 'Recall', 'F1 Score', \n",
        "               'HD95 (pixels)', 'ASD (pixels)', 'Specificity'],\n",
        "    'Mean': [\n",
        "        np.mean(test_dice), \n",
        "        np.mean(test_iou), \n",
        "        np.mean(test_prec), \n",
        "        np.mean(test_rec), \n",
        "        np.mean(test_f1),\n",
        "        np.mean(test_hd95), \n",
        "        np.mean(test_asd),\n",
        "        specificity\n",
        "    ],\n",
        "    'Std': [\n",
        "        np.std(test_dice), \n",
        "        np.std(test_iou), \n",
        "        np.std(test_prec), \n",
        "        np.std(test_rec), \n",
        "        np.std(test_f1),\n",
        "        np.std(test_hd95), \n",
        "        np.std(test_asd),\n",
        "        0  # Single value\n",
        "    ],\n",
        "    'Median': [\n",
        "        np.median(test_dice), \n",
        "        np.median(test_iou), \n",
        "        np.median(test_prec), \n",
        "        np.median(test_rec), \n",
        "        np.median(test_f1),\n",
        "        np.median(test_hd95), \n",
        "        np.median(test_asd),\n",
        "        specificity\n",
        "    ],\n",
        "    'Min': [\n",
        "        np.min(test_dice), \n",
        "        np.min(test_iou), \n",
        "        np.min(test_prec), \n",
        "        np.min(test_rec), \n",
        "        np.min(test_f1),\n",
        "        np.min(test_hd95), \n",
        "        np.min(test_asd),\n",
        "        specificity\n",
        "    ],\n",
        "    'Max': [\n",
        "        np.max(test_dice), \n",
        "        np.max(test_iou), \n",
        "        np.max(test_prec), \n",
        "        np.max(test_rec), \n",
        "        np.max(test_f1),\n",
        "        np.max(test_hd95), \n",
        "        np.max(test_asd),\n",
        "        specificity\n",
        "    ]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_stats)\n",
        "print(summary_df.to_string(index=False))\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save to CSV\n",
        "summary_df.to_csv('test_evaluation_summary.csv', index=False)\n",
        "print(\"\\nâœ… Summary saved to 'test_evaluation_summary.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10. Violin Plot - Detailed Distribution Comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Segmentation metrics violin plot\n",
        "ax1 = axes[0]\n",
        "parts1 = ax1.violinplot([test_dice, test_iou, test_prec, test_rec, test_f1], \n",
        "                         positions=range(1, 6), showmeans=True, showmedians=True)\n",
        "\n",
        "for pc in parts1['bodies']:\n",
        "    pc.set_facecolor('lightblue')\n",
        "    pc.set_alpha(0.7)\n",
        "\n",
        "ax1.set_xticks(range(1, 6))\n",
        "ax1.set_xticklabels(['Dice', 'IoU', 'Precision', 'Recall', 'F1'])\n",
        "ax1.set_ylabel('Score', fontsize=12)\n",
        "ax1.set_title('Violin Plot - Segmentation Metrics', fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "ax1.set_ylim([0, 1.05])\n",
        "\n",
        "# Distance metrics violin plot\n",
        "ax2 = axes[1]\n",
        "parts2 = ax2.violinplot([test_hd95, test_asd], positions=[1, 2], \n",
        "                         showmeans=True, showmedians=True)\n",
        "\n",
        "for pc in parts2['bodies']:\n",
        "    pc.set_facecolor('lightcoral')\n",
        "    pc.set_alpha(0.7)\n",
        "\n",
        "ax2.set_xticks([1, 2])\n",
        "ax2.set_xticklabels(['HD95', 'ASD'])\n",
        "ax2.set_ylabel('Distance (pixels)', fontsize=12)\n",
        "ax2.set_title('Violin Plot - Distance Metrics', fontsize=14, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('violin_plots_metrics.png', dpi=300)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
